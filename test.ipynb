{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.CapsuleLayer import CapsuleRouting\n",
    "import torch\n",
    "routing = CapsuleRouting(mode='em')\n",
    "\n",
    "v = torch.rand(2, 8, 10, 16, 1, 1)\n",
    "a = torch.rand(2, 8, 1, 1)\n",
    "v, a = routing(v, a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.CapsuleLayer import AdaptiveCapsuleHead\n",
    "import torch\n",
    "\n",
    "model = AdaptiveCapsuleHead(32, 10, 4, 1, False, *[\"dynamic\", 10, 1.5])\n",
    "v = torch.rand(2, 32, 5, 5)\n",
    "\n",
    "out, v = model(v, get_capsules=True)\n",
    "print(v.shape)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from Capsule.Layer.Classifier import CapsuleWrappingClassifier\n",
    "with open('config/new-config.yml', 'r') as stream:\n",
    "    PARAMS = yaml.safe_load(stream)\n",
    "    print(PARAMS)\n",
    "model = CapsuleWrappingClassifier(model_configs=PARAMS['architect_settings'])\n",
    "\n",
    "img = torch.rand(2, 3, 224, 224)\n",
    "\n",
    "out = model(img)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.ultis import Cub2011\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms import ToPILImage\n",
    "dataset = Cub2011(mode='test', data_path='data/CUB_200_2011', transform=None)\n",
    "\n",
    "img, label, oimg = dataset[10]\n",
    "print(label)\n",
    "plt.imshow(ToPILImage()(oimg))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(60.).reshape(3,4,5)\n",
    "b = np.arange(24.).reshape(4,3,2)\n",
    "print(a)\n",
    "print(b)\n",
    "np.einsum('ijk,jil->kl', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A = torch.rand(2, 15, 4, 4, 3, 3)\n",
    "B = torch.rand(15, 4, 4, 8)\n",
    "v = torch.einsum('bBijHW, BjkC -> bBCikHW', A, B)\n",
    "print(v.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS =  {\n",
    "    \"architect_settings\" : {\n",
    "            \"task\": \"None\",\n",
    "            \"name\": \"model-test\",\n",
    "            \"backbone\": {\n",
    "                    \"name\": \"resnet-s\",\n",
    "                    \"is_full\": False,\n",
    "                    \"is_pretrained\": True,\n",
    "                    \"is_feats\": False,\n",
    "                    \"is_freeze\": True, \n",
    "            },\n",
    "            \"n_cls\": 2,\n",
    "            \"is_caps\": False,\n",
    "            \"caps\":{\n",
    "                \"mode\": 1,\n",
    "                \"cap_dims\": 4,\n",
    "                \"routing\":{\n",
    "                        \"type\": \"dynamic\",\n",
    "                        \"params\": [3, 0.01, 1.5]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "    \"dataset_settings\": {\n",
    "            \n",
    "            },\n",
    "    \"training_settings\":{\n",
    "    \n",
    "    }\n",
    "}\n",
    "\n",
    "from Capsule.Layer.Classifier import CapsuleWrappingClassifier\n",
    "from Capsule.ultis import Cub2011, CIFAR10read\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "model = CapsuleWrappingClassifier(model_configs=PARAMS[\"architect_settings\"])\n",
    "model.eval()\n",
    "\n",
    "def get_train_data(model, dataloder):\n",
    "    train_data = []\n",
    "    train_label = []    \n",
    "    for batch in dataloder:\n",
    "        img, label, oimg = batch\n",
    "        feats = model.backbone(img)\n",
    "        out = feats.reshape(-1, 512, 7, 7)\n",
    "        train_data.append(out.detach().numpy())\n",
    "        train_label.append(label.detach().numpy())\n",
    "\n",
    "    train_data = np.concatenate(train_data, axis=0)\n",
    "    train_label = np.concatenate(train_label, axis=0)\n",
    "    print(train_data.shape)\n",
    "    print(train_label.shape)\n",
    "    return train_data, train_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10read(mode=\"train\", data_path=\"data\")\n",
    "dataloder = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "train_data, train_label = get_train_data(model, dataloder)\n",
    "\n",
    "hf = h5py.File('data/CIFAR10_train_data.h5', 'w')\n",
    "hf.create_dataset('data', data=train_data)\n",
    "hf.create_dataset('label', data=train_label)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10read(mode=\"test\", data_path=\"data\")\n",
    "dataloder = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "test_data, test_label = get_train_data(model, dataloder)\n",
    "\n",
    "hf = h5py.File('data/CIFAR10_test_data.h5', 'w')\n",
    "hf.create_dataset('data', data=test_data)\n",
    "hf.create_dataset('label', data=test_label)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import h5py\n",
    "\n",
    "hf = h5py.File('data/CIFAR10_train_data.h5', 'r')\n",
    "train_data = np.array(hf['data'])\n",
    "train_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "hf = h5py.File('data/CIFAR10_test_data.h5', 'r')\n",
    "test_data = np.array(hf['data'])\n",
    "test_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "\n",
    "train_data = np.mean(train_data, axis=(2, 3))\n",
    "test_data = np.mean(test_data, axis=(2, 3))\n",
    "\n",
    "#scikit-learn MLPClassifier on train_data, train_label\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512, 512), max_iter=1000)\n",
    "clf.fit(train_data, train_label)\n",
    "accuracy_score(clf.predict(test_data), test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(train_data, train_label)\n",
    "accuracy_score(clf.predict(train_data), train_label)\n",
    "accuracy_score(clf.predict(test_data), test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "hf = h5py.File('data/CUB_ResNet_train_data.h5', 'r')\n",
    "train_data = np.array(hf['data'])\n",
    "train_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "\n",
    "tensor_x = torch.Tensor(train_data) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(train_label)\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "train_loader = DataLoader(my_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('data/CUB_ResNet_test_data.h5', 'r')\n",
    "test_data = np.array(hf['data'])\n",
    "test_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "\n",
    "tensor_x = torch.Tensor(test_data) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(test_label)\n",
    "my_val_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "valid_loader = DataLoader(my_val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from Capsule.CapsuleLayer import AdaptiveCapsuleHead\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "                AdaptiveCapsuleHead(512, 200,\n",
    "                4, 4, True, \n",
    "                *['dynamic', 3, 2]),\n",
    "                # nn.LogSoftmax(dim=1),\n",
    "                nn.Flatten(start_dim=1)\n",
    "            )\n",
    "\n",
    "# Define the classifier on top of the ResNet\n",
    "# classifier = nn.Sequential(\n",
    "#     nn.Linear(512, 512, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512, 1),\n",
    "#     # nn.LogSoftmax(dim=1),\n",
    "#     # nn.Flatten(start_dim=1)\n",
    "# )\n",
    "\n",
    "# # Combine the ResNet and classifier\n",
    "# from torchvision.models import resnet18\n",
    "# resnet = resnet18(pretrained=True)\n",
    "# resnet.fc = nn.Identity()\n",
    "# model = nn.Sequential(resnet, classifier)\n",
    "model = classifier.to(device)\n",
    "# Load the MNIST dataset\n",
    "# train_dataset = Cub2011(mode=\"train\", data_path=\"data/CUB_200_2011\")\n",
    "# valid_dataset = Cub2011(mode=\"val\", data_path=\"data/CUB_200_2011\")\n",
    "\n",
    "# # Set hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "max_val = 0\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/ {num_epochs} - Training\"):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "        # print(images, labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute average training accuracy and loss\n",
    "    train_accuracy = 100.0 * train_correct / total_train_samples\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_correct = 0\n",
    "    total_valid_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader, desc=f\"Epoch {epoch + 1}/ {num_epochs} - Validation\"):\n",
    "            # Forward pass\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            valid_correct += (predicted == labels).sum().item()\n",
    "            total_valid_samples += labels.size(0)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    # Compute average validation accuracy and loss\n",
    "    valid_accuracy = 100.0 * valid_correct / total_valid_samples\n",
    "    valid_loss /= len(valid_loader)\n",
    "    if(valid_accuracy > max_val):\n",
    "        max_val = valid_accuracy\n",
    "    # Print epoch-wise results\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Accuracy: {valid_accuracy:.2f}%\")\n",
    "print(f\"Max Valid Accuracy: {max_val:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUB\n",
    "- CUB-resnet-sci-SVM: 0.5904\n",
    "- CUB-resnet-freeze-2hMLP: 0.5856\n",
    "- CUB-resnet-sci-MLP: 0.577\n",
    "\n",
    "CIFAR\n",
    "- CIFAR-resnet-sci-MLP: 0.8717\n",
    "- CIFAR-resnet-sci-SVM: 0.8822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.CapsuleLayer import CapsuleRouting\n",
    "import torch\n",
    "p = torch.randn(2, 32, 16, 4, 4)\n",
    "a = torch.randn(2, 32, 4, 4)\n",
    "params = {\"reduce\": True,\n",
    "        \"cap_dims\": 4,\n",
    "        \"routing\":{\n",
    "                \"type\": \"em\",\n",
    "                \"iters\": 3,\n",
    "                \"temp\": 1.5,\n",
    "        }\n",
    "}\n",
    "\n",
    "dynamic_routing = CapsuleRouting(B=32, C=10, caps=params)\n",
    "dynamic_routing.eval()\n",
    "v_out, a_out = dynamic_routing(p, a)\n",
    "print(v_out.shape, a_out.shape)\n",
    "print(a_out, v_out)\n",
    "# print(dynamic_routing.W_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 1, 1])\n",
      "tensor([[[[4.8726]],\n",
      "\n",
      "         [[4.8772]],\n",
      "\n",
      "         [[4.7810]],\n",
      "\n",
      "         [[4.7878]],\n",
      "\n",
      "         [[4.8151]],\n",
      "\n",
      "         [[4.9268]],\n",
      "\n",
      "         [[4.9756]],\n",
      "\n",
      "         [[4.8725]],\n",
      "\n",
      "         [[4.6878]],\n",
      "\n",
      "         [[4.8122]]],\n",
      "\n",
      "\n",
      "        [[[4.7939]],\n",
      "\n",
      "         [[4.7739]],\n",
      "\n",
      "         [[4.6199]],\n",
      "\n",
      "         [[4.7252]],\n",
      "\n",
      "         [[4.6583]],\n",
      "\n",
      "         [[4.8303]],\n",
      "\n",
      "         [[4.8389]],\n",
      "\n",
      "         [[4.7830]],\n",
      "\n",
      "         [[4.6639]],\n",
      "\n",
      "         [[4.7117]]]], grad_fn=<LogBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Capsule.CapsuleLayer import AdaptiveCapsuleHead\n",
    "import torch\n",
    "p = torch.randn(2, 512, 7, 7)\n",
    "# a = torch.randn(2, 512, 7, 7)\n",
    "params = {\n",
    "    \"n_cls\": 10,\n",
    "    \"n_layers\": 2,\n",
    "    \"n_emb\": 512,\n",
    "    \"is_caps\": False,\n",
    "    \"caps\": {\n",
    "        \"pooling\": \"None\",\n",
    "        \"shuffle\": True,\n",
    "        \"cap_style\": \"c\", # c: by channel, hw: by height and width\n",
    "        \"cap_dims\": 4,\n",
    "        \"routing\":{\n",
    "            \"reduce\": True,\n",
    "            \"type\": \"dynamic\",\n",
    "            \"iters\": 3,\n",
    "            \"temp\": 1.5,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "adaptive_capsule_head = AdaptiveCapsuleHead(512, head=params)\n",
    "adaptive_capsule_head.eval()\n",
    "a_out = adaptive_capsule_head(p)\n",
    "print(a_out.shape)\n",
    "print(a_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.CapsuleLayer import ProjectionHead\n",
    "import torch\n",
    "p = torch.randn(2, 512, 7, 7)\n",
    "\n",
    "projection_head = ProjectionHead(512, 32, 1)\n",
    "print(projection_head)\n",
    "out = projection_head(p)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptivePoolCapsuleHead(nn.Module):\n",
    "    '''\n",
    "    Capsule Header combines of Primary Capsule and Linear Capsule.\n",
    "    \n",
    "    - Arguments:\n",
    "        B: number of capsule in L layer\n",
    "        C: number of capsule in L + 1 layer\n",
    "        get_capsules: Return Capsules's vector\n",
    "        P: size of a capsule\n",
    "        reduce: reduce the featrue maps before routing\n",
    "        args: arguments for routing method\n",
    "        argv[0]: routing method\n",
    "        argv[1]: number of iteration\n",
    "        argv[2]: m for fuzzy routing\n",
    "    '''\n",
    "    def __init__(self, B, head):\n",
    "        super(AdaptivePoolCapsuleHead, self).__init__()\n",
    "     \n",
    "  \n",
    "        self.reduce = head['caps']['reduce']\n",
    "        self.n_layers = head['n_layers']\n",
    "        n_emb = head['n_emb']\n",
    "        self.P = head['caps']['cap_dims']\n",
    "\n",
    "        assert B % (self.P * self.P) == 0, \"channel is not divisible by P * P\"\n",
    "        self.B = B // (self.P * self.P)\n",
    "        assert n_emb % (self.P * self.P) == 0, \"embedding is not divisible by P * P\"\n",
    "        self.n_emb = n_emb // (self.P * self.P)\n",
    "      \n",
    "        self.primary_capsule = nn.Sequential()\n",
    "        self.a_routing = nn.Sequential()\n",
    "        if(self.reduce):\n",
    "            self.primary_capsule.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "            self.a_routing.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        if(self.n_layers == 1):\n",
    "            self.primary_capsule.append(nn.Identity())\n",
    "            self.routinglayer = CapsuleRouting(self.B, head['n_cls'], head['caps'])\n",
    "        else:\n",
    "            self.primary_capsule.append(nn.Conv2d(B, n_emb, 1))\n",
    "            self.primary_capsule.append(nn.ReLU())\n",
    "            for i in range(1, self.n_layers - 1):\n",
    "                self.primary_capsule.append(nn.Conv2d(n_emb, n_emb, 1))\n",
    "                if(i < self.n_layers - 1):\n",
    "                    self.primary_capsule.append(nn.ReLU())\n",
    "            self.routinglayer = CapsuleRouting(self.n_emb, head['n_cls'], head['caps'])\n",
    "\n",
    "        self.a_routing.append(nn.Conv2d(B, self.B, 1))\n",
    "\n",
    "    def forward(self, x, get_capsules=False):\n",
    "        '''\n",
    "        input: \n",
    "            tensor 4D (b, B, h, w)\n",
    "        output:\n",
    "            capsule 3D (b, C, P*P) / 5D (b, C, P*P, h, w)\n",
    "            activation 2D (b, C) / 5D (b, C, h, w)\n",
    "        '''\n",
    "        # Primary capsule\n",
    "        \n",
    "        # p <- (b, B, P * P, h, w)\n",
    "        # a <- (b, B, h, w)\n",
    "        p = self.primary_capsule(x)\n",
    "        # x <- (b, C, h, w)\n",
    "        b, d, h, w =  p.shape\n",
    "        p = p.reshape(b, self.B , self.P ** 2, h, w)\n",
    "       \n",
    "        a = self.a_routing(x)\n",
    "        a = torch.sigmoid(a)\n",
    "        \n",
    "        print(p.shape, a.shape)\n",
    "        p_out, a_out = self.routinglayer(p, a)\n",
    "        a_out = torch.log(a_out / (1 - a_out + EPS))\n",
    "       \n",
    "        if get_capsules:\n",
    "            return p_out, a_out\n",
    "        else: \n",
    "            return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  2.0108e-08, -1.1174e-07],\n",
      "        [ 2.0108e-08,  1.0000e+00,  5.6405e-08],\n",
      "        [-1.1174e-07,  5.6405e-08,  1.0000e+00]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "orthogonal_weight = torch.nn.utils.parametrizations.orthogonal(nn.Conv2d(2, 2, 3))\n",
    "print(orthogonal_weight.weight[0][0].T @ orthogonal_weight.weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logger': {'project': 'kaori/Capsule-Network', 'api_key': 'YOUR API KEY', 'tags': 'None'}, 'task': 'classification', 'architect_settings': {'backbone': {'name': 'fcn-m', 'is_backbone': True, 'is_full': False, 'is_pretrained': False, 'is_freeze': False}, 'head': {'n_cls': 10, 'n_layers': 3, 'n_emb': 512, 'is_caps': True, 'caps': {'pooling': 'None', 'shuffle': False, 'cap_style': 'c', 'reduce': 'None', 'cap_dims': 4, 'routing': {'type': 'dynamic', 'iters': 3, 'temp': 1.5}}}}, 'dataset_settings': {'name': 'CIFAR10-feats', 'path': 'data/', 'img_size': 224}, 'training_settings': {'gpu_ids': [0], 'n_gpu': 1, 'loss': 'ce', 'metric': 'accuracy', 'ckpt_path': './mode/test', 'n_epoch': 100, 'n_batch': 64, 'num_workers': 0, 'optimizer': 'adam', 'lr_scheduler': 'step', 'early_stopping': True, 'lr': 0.0001, 'lr_step': 5, 'lr_decay': 0.8, 'momentum': 0.9, 'weight_decay': 0.005}}\n",
      "CapsuleWrappingSegment(\n",
      "  (preprocess): SemanticSegmentation(\n",
      "      resize_size=[520]\n",
      "      mean=[0.485, 0.456, 0.406]\n",
      "      std=[0.229, 0.224, 0.225]\n",
      "      interpolation=InterpolationMode.BILINEAR\n",
      "  )\n",
      "  (backbone): FCN(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): AdaptiveCapsuleHead(\n",
      "      (primary_capsule): Sequential(\n",
      "        (projection): ProjectionHead(\n",
      "          (projection): Sequential(\n",
      "            (conv0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (relu0): ReLU()\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (relu1): ReLU()\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (activation): Sequential(\n",
      "        (projection): ProjectionHead(\n",
      "          (projection): Sequential(\n",
      "            (conv0): Conv2d(2048, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (relu0): ReLU()\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (routinglayer): CapsuleRouting()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 10, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from Capsule.model import CapsuleWrappingClassifier, CapsuleWrappingSegment\n",
    "import yaml\n",
    "with open('config/new-config.yml', 'r') as stream:\n",
    "        PARAMS = yaml.safe_load(stream)\n",
    "        print(PARAMS)\n",
    "\n",
    "model = CapsuleWrappingSegment(PARAMS['architect_settings'])\n",
    "\n",
    "import torch\n",
    "x = torch.randn(2, 3, 224, 224)\n",
    "out = model(x)\n",
    "print(model)\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
