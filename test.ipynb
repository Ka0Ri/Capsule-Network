{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_Capsule.Model import CapNets\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variational Bayes Capsule\n",
    "Training time: 245m 5s\n",
    "\n",
    "Best Valid: Epoch 218 - Loss 2.1469 - Acc. 0.4158\n",
    "Test: Loss 2.1520 - Acc. 0.4049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6459, 0.5897, 0.6250, 0.6997, 0.5939, 0.5469, 0.6405, 0.6533, 0.6025,\n",
      "         0.6558],\n",
      "        [0.5997, 0.6620, 0.5880, 0.5970, 0.6174, 0.5866, 0.6309, 0.6903, 0.6670,\n",
      "         0.6090]], device='cuda:0', grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "architect_settings = {\n",
    "    \"name\": \"convcaps\",\n",
    "    \"reconstructed\": True,\n",
    "    \"n_cls\": 10,\n",
    "    \"convs\": {\n",
    "            \"channels\": [1, 64],\n",
    "            \"k\": 4,\n",
    "            \"s\": 4,\n",
    "            \"p\": 0},\n",
    "    \"primay_caps\": {\n",
    "            \"channels\": [64, 32],\n",
    "            \"k\": 3,\n",
    "            \"s\": 3,\n",
    "            \"p\": 0},\n",
    "    \"caps\": {\n",
    "            \"init\": \"noisy_identity\",\n",
    "            \"cap_dims\": 4,\n",
    "            \"channels\": [32, 10],\n",
    "            \"k\": 3,\n",
    "            \"s\": 1,\n",
    "            \"p\": 0,\n",
    "            \"routing\": {\n",
    "                \"type\": \"fuzzy\",\n",
    "                \"params\" : [3]}}\n",
    "    }\n",
    "\n",
    "architect_settings_2 = {\n",
    "        \"name\": \"capsconv\",\n",
    "        \"reconstructed\": True,\n",
    "        \"n_cls\": 10,\n",
    "        \"convs\": {\n",
    "                \"channels\": [1, 64, 128],\n",
    "                \"k\": 5,\n",
    "                \"s\": 2,\n",
    "                \"p\": 2},\n",
    "        \"primay_caps\": {\n",
    "                \"channels\": [128, 32],\n",
    "                \"k\": 3,\n",
    "                \"s\": 2,\n",
    "                \"p\": 1},\n",
    "        \"caps\": {\n",
    "                \"init\": \"noisy_identity\",\n",
    "                \"cap_dims\": 4,\n",
    "                \"channels\": [32, 16, 10],\n",
    "                \"k\": 3,\n",
    "                \"s\": 1,\n",
    "                \"p\": 0,\n",
    "                \"routing\": {\n",
    "                        \"type\": \"em\",\n",
    "                        \"params\" : [5]}}\n",
    "        }\n",
    "# model = ConvNeuralNet(model_configs=architect_settings).cuda()\n",
    "model = CapNets(model_configs=architect_settings).cuda()\n",
    "input_tensor = torch.rand(2, 1, 40, 40).cuda()\n",
    "y = torch.tensor([2, 4]).cuda()\n",
    "a, re = model(input_tensor, y)\n",
    "print(a)\n",
    "# print(a.shape)\n",
    "# print(re.shape)\n",
    "# print(torch.softmax(a, dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
