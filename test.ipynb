{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.Layer.CapsuleLayer import CapsuleRouting\n",
    "import torch\n",
    "routing = CapsuleRouting(mode='em')\n",
    "\n",
    "v = torch.rand(2, 8, 10, 16, 1, 1)\n",
    "a = torch.rand(2, 8, 1, 1)\n",
    "v, a = routing(v, a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.Layer.CapsuleLayer import AdaptiveCapsuleHead\n",
    "import torch\n",
    "\n",
    "model = AdaptiveCapsuleHead(32, 10, 4, 1, False, *[\"dynamic\", 10, 1.5])\n",
    "v = torch.rand(2, 32, 5, 5)\n",
    "\n",
    "out, v = model(v, get_capsules=True)\n",
    "print(v.shape)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from Capsule.Layer.Classifier import CapsuleWrappingClassifier\n",
    "with open('config/new-config.yml', 'r') as stream:\n",
    "    PARAMS = yaml.safe_load(stream)\n",
    "    print(PARAMS)\n",
    "model = CapsuleWrappingClassifier(model_configs=PARAMS['architect_settings'])\n",
    "\n",
    "img = torch.rand(2, 3, 224, 224)\n",
    "\n",
    "out = model(img)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.ultis import Cub2011\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms import ToPILImage\n",
    "dataset = Cub2011(mode='test', data_path='data/CUB_200_2011', transform=None)\n",
    "\n",
    "img, label, oimg = dataset[10]\n",
    "print(label)\n",
    "plt.imshow(ToPILImage()(oimg))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(60.).reshape(3,4,5)\n",
    "b = np.arange(24.).reshape(4,3,2)\n",
    "print(a)\n",
    "print(b)\n",
    "np.einsum('ijk,jil->kl', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A = torch.rand(2, 15, 4, 4, 3, 3)\n",
    "B = torch.rand(15, 4, 4, 8)\n",
    "v = torch.einsum('bBijHW, BjkC -> bBCikHW', A, B)\n",
    "print(v.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS =  {\n",
    "    \"architect_settings\" : {\n",
    "            \"task\": \"None\",\n",
    "            \"name\": \"model-test\",\n",
    "            \"backbone\": {\n",
    "                    \"name\": \"resnet-s\",\n",
    "                    \"is_full\": False,\n",
    "                    \"is_pretrained\": True,\n",
    "                    \"is_feats\": False,\n",
    "                    \"is_freeze\": True, \n",
    "            },\n",
    "            \"n_cls\": 2,\n",
    "            \"is_caps\": False,\n",
    "            \"caps\":{\n",
    "                \"mode\": 1,\n",
    "                \"cap_dims\": 4,\n",
    "                \"routing\":{\n",
    "                        \"type\": \"dynamic\",\n",
    "                        \"params\": [3, 0.01, 1.5]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "    \"dataset_settings\": {\n",
    "            \n",
    "            },\n",
    "    \"training_settings\":{\n",
    "    \n",
    "    }\n",
    "}\n",
    "\n",
    "from Capsule.Layer.Classifier import CapsuleWrappingClassifier\n",
    "from Capsule.ultis import Cub2011, CIFAR10read\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "model = CapsuleWrappingClassifier(model_configs=PARAMS[\"architect_settings\"])\n",
    "model.eval()\n",
    "\n",
    "def get_train_data(model, dataloder):\n",
    "    train_data = []\n",
    "    train_label = []    \n",
    "    for batch in dataloder:\n",
    "        img, label, oimg = batch\n",
    "        feats = model.backbone(img)\n",
    "        out = feats.reshape(-1, 512, 7, 7)\n",
    "        train_data.append(out.detach().numpy())\n",
    "        train_label.append(label.detach().numpy())\n",
    "\n",
    "    train_data = np.concatenate(train_data, axis=0)\n",
    "    train_label = np.concatenate(train_label, axis=0)\n",
    "    print(train_data.shape)\n",
    "    print(train_label.shape)\n",
    "    return train_data, train_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10read(mode=\"train\", data_path=\"data\")\n",
    "dataloder = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "train_data, train_label = get_train_data(model, dataloder)\n",
    "\n",
    "hf = h5py.File('data/CIFAR10_train_data.h5', 'w')\n",
    "hf.create_dataset('data', data=train_data)\n",
    "hf.create_dataset('label', data=train_label)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10read(mode=\"test\", data_path=\"data\")\n",
    "dataloder = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "test_data, test_label = get_train_data(model, dataloder)\n",
    "\n",
    "hf = h5py.File('data/CIFAR10_test_data.h5', 'w')\n",
    "hf.create_dataset('data', data=test_data)\n",
    "hf.create_dataset('label', data=test_label)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import h5py\n",
    "\n",
    "hf = h5py.File('data/CIFAR10_train_data.h5', 'r')\n",
    "train_data = np.array(hf['data'])\n",
    "train_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "hf = h5py.File('data/CIFAR10_test_data.h5', 'r')\n",
    "test_data = np.array(hf['data'])\n",
    "test_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "\n",
    "train_data = np.mean(train_data, axis=(2, 3))\n",
    "test_data = np.mean(test_data, axis=(2, 3))\n",
    "\n",
    "#scikit-learn MLPClassifier on train_data, train_label\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512, 512), max_iter=1000)\n",
    "clf.fit(train_data, train_label)\n",
    "accuracy_score(clf.predict(test_data), test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(train_data, train_label)\n",
    "accuracy_score(clf.predict(train_data), train_label)\n",
    "accuracy_score(clf.predict(test_data), test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "hf = h5py.File('data/CUB_ResNet_train_data.h5', 'r')\n",
    "train_data = np.array(hf['data'])\n",
    "train_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "\n",
    "tensor_x = torch.Tensor(train_data) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(train_label)\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "train_loader = DataLoader(my_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('data/CUB_ResNet_test_data.h5', 'r')\n",
    "test_data = np.array(hf['data'])\n",
    "test_label = np.array(hf['label'])\n",
    "hf.close()\n",
    "\n",
    "tensor_x = torch.Tensor(test_data) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(test_label)\n",
    "my_val_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "valid_loader = DataLoader(my_val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from Capsule.Layer.CapsuleLayer import AdaptiveCapsuleHead\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "                AdaptiveCapsuleHead(512, 200,\n",
    "                4, 4, True, \n",
    "                *['dynamic', 3, 2]),\n",
    "                # nn.LogSoftmax(dim=1),\n",
    "                nn.Flatten(start_dim=1)\n",
    "            )\n",
    "\n",
    "# Define the classifier on top of the ResNet\n",
    "# classifier = nn.Sequential(\n",
    "#     nn.Linear(512, 512, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512, 1),\n",
    "#     # nn.LogSoftmax(dim=1),\n",
    "#     # nn.Flatten(start_dim=1)\n",
    "# )\n",
    "\n",
    "# # Combine the ResNet and classifier\n",
    "# from torchvision.models import resnet18\n",
    "# resnet = resnet18(pretrained=True)\n",
    "# resnet.fc = nn.Identity()\n",
    "# model = nn.Sequential(resnet, classifier)\n",
    "model = classifier.to(device)\n",
    "# Load the MNIST dataset\n",
    "# train_dataset = Cub2011(mode=\"train\", data_path=\"data/CUB_200_2011\")\n",
    "# valid_dataset = Cub2011(mode=\"val\", data_path=\"data/CUB_200_2011\")\n",
    "\n",
    "# # Set hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "max_val = 0\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/ {num_epochs} - Training\"):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "        # print(images, labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute average training accuracy and loss\n",
    "    train_accuracy = 100.0 * train_correct / total_train_samples\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_correct = 0\n",
    "    total_valid_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader, desc=f\"Epoch {epoch + 1}/ {num_epochs} - Validation\"):\n",
    "            # Forward pass\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            valid_correct += (predicted == labels).sum().item()\n",
    "            total_valid_samples += labels.size(0)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    # Compute average validation accuracy and loss\n",
    "    valid_accuracy = 100.0 * valid_correct / total_valid_samples\n",
    "    valid_loss /= len(valid_loader)\n",
    "    if(valid_accuracy > max_val):\n",
    "        max_val = valid_accuracy\n",
    "    # Print epoch-wise results\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Accuracy: {valid_accuracy:.2f}%\")\n",
    "print(f\"Max Valid Accuracy: {max_val:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUB\n",
    "- CUB-resnet-sci-SVM: 0.5904\n",
    "- CUB-resnet-freeze-2hMLP: 0.5856\n",
    "- CUB-resnet-sci-MLP: 0.577\n",
    "\n",
    "CIFAR\n",
    "- CIFAR-resnet-sci-MLP: 0.8717\n",
    "- CIFAR-resnet-sci-SVM: 0.8822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capsule.Layer.CapsuleLayer import CapsuleRouting\n",
    "import torch\n",
    "p = torch.randn(2, 32, 16, 4, 4)\n",
    "a = torch.randn(2, 32, 4, 4)\n",
    "params = {\"reduce\": True,\n",
    "        \"cap_dims\": 4,\n",
    "        \"routing\":{\n",
    "                \"type\": \"em\",\n",
    "                \"iters\": 3,\n",
    "                \"temp\": 1.5,\n",
    "        }\n",
    "}\n",
    "\n",
    "dynamic_routing = CapsuleRouting(B=32, C=10, caps=params)\n",
    "dynamic_routing.eval()\n",
    "v_out, a_out = dynamic_routing(p, a)\n",
    "print(v_out.shape, a_out.shape)\n",
    "print(a_out, v_out)\n",
    "# print(dynamic_routing.W_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 7, 7])\n",
      "tensor([[[[0.4392, 0.6196, 0.3870, 0.6189, 0.4758, 0.4963, 0.5582],\n",
      "          [0.3924, 0.4250, 0.2292, 0.3699, 0.3453, 0.3696, 0.3428],\n",
      "          [0.3476, 0.3348, 0.4238, 0.4455, 0.3796, 0.5365, 0.4065],\n",
      "          [0.5630, 0.5541, 0.5370, 0.5874, 0.4954, 0.2462, 0.5383],\n",
      "          [0.2839, 0.5873, 0.4230, 0.6486, 0.5276, 0.2602, 0.3095],\n",
      "          [0.5296, 0.3232, 0.4238, 0.4315, 0.4439, 0.4921, 0.2142],\n",
      "          [0.4880, 0.3745, 0.4630, 0.4667, 0.3553, 0.4218, 0.2761]],\n",
      "\n",
      "         [[0.5361, 0.6148, 0.4635, 0.3694, 0.3350, 0.3384, 0.3515],\n",
      "          [0.2066, 0.5073, 0.3386, 0.2597, 0.7618, 0.3021, 0.6784],\n",
      "          [0.7536, 0.5003, 0.4151, 0.4471, 0.4659, 0.2336, 0.3833],\n",
      "          [0.3045, 0.4223, 0.3703, 0.3941, 0.5521, 0.5707, 0.3556],\n",
      "          [0.4565, 0.3918, 0.3009, 0.4429, 0.3053, 0.3054, 0.4414],\n",
      "          [0.3762, 0.6532, 0.4667, 0.2745, 0.3887, 0.4153, 0.5789],\n",
      "          [0.6327, 0.4433, 0.4853, 0.3734, 0.6871, 0.4807, 0.3179]],\n",
      "\n",
      "         [[0.5100, 0.4274, 0.4609, 0.4034, 0.2820, 0.4175, 0.5589],\n",
      "          [0.3568, 0.4147, 0.5402, 0.4393, 0.4196, 0.4755, 0.3531],\n",
      "          [0.4858, 0.5342, 0.4842, 0.3900, 0.2660, 0.3879, 0.3246],\n",
      "          [0.3654, 0.3753, 0.5858, 0.3568, 0.3938, 0.5086, 0.4037],\n",
      "          [0.4954, 0.4663, 0.7951, 0.3539, 0.4105, 0.2383, 0.6076],\n",
      "          [0.2872, 0.2648, 0.2995, 0.3078, 0.4270, 0.6391, 0.3439],\n",
      "          [0.4094, 0.3544, 0.5288, 0.3558, 0.3872, 0.3649, 0.5116]],\n",
      "\n",
      "         [[0.4977, 0.4602, 0.4029, 0.3274, 0.6194, 0.7943, 0.6619],\n",
      "          [0.4291, 0.3821, 0.7327, 0.5004, 0.2965, 0.4025, 0.5114],\n",
      "          [0.5494, 0.3783, 0.4664, 0.6632, 0.4173, 0.5877, 0.5691],\n",
      "          [0.4027, 0.4597, 0.4629, 0.3076, 0.4038, 0.4138, 0.4552],\n",
      "          [0.4490, 0.4438, 0.7535, 0.5016, 0.5579, 0.6142, 0.5539],\n",
      "          [0.3937, 0.4097, 0.5570, 0.3801, 0.2960, 0.4636, 0.5352],\n",
      "          [0.5233, 0.5136, 0.3963, 0.3505, 0.6237, 0.4142, 0.7395]],\n",
      "\n",
      "         [[0.4300, 0.4928, 0.3506, 0.3686, 0.4033, 0.4525, 0.2336],\n",
      "          [0.3346, 0.5093, 0.2443, 0.3237, 0.4595, 0.2873, 0.5043],\n",
      "          [0.3712, 0.3402, 0.2042, 0.4955, 0.3547, 0.4837, 0.3738],\n",
      "          [0.5497, 0.5579, 0.3410, 0.3343, 0.3843, 0.3257, 0.2067],\n",
      "          [0.4941, 0.2906, 0.4167, 0.3817, 0.2602, 0.6092, 0.6107],\n",
      "          [0.5104, 0.6520, 0.3465, 0.3918, 0.3738, 0.3258, 0.4365],\n",
      "          [0.2621, 0.3931, 0.5031, 0.3951, 0.3909, 0.6675, 0.2712]],\n",
      "\n",
      "         [[0.4520, 0.5640, 0.4204, 0.6664, 0.7420, 0.5358, 0.5517],\n",
      "          [0.6660, 0.4124, 0.4418, 0.4369, 0.4030, 0.5681, 0.3110],\n",
      "          [0.5303, 0.4485, 0.2567, 0.4187, 0.3541, 0.3938, 0.6174],\n",
      "          [0.4908, 0.3995, 0.3043, 0.4309, 0.5112, 0.7356, 0.3241],\n",
      "          [0.4660, 0.6932, 0.5959, 0.3611, 0.4129, 0.3660, 0.4558],\n",
      "          [0.5788, 0.5192, 0.5242, 0.5301, 0.4815, 0.4211, 0.3602],\n",
      "          [0.2564, 0.3565, 0.5633, 0.4708, 0.2998, 0.4949, 0.4627]],\n",
      "\n",
      "         [[0.3551, 0.3318, 0.5023, 0.2245, 0.4357, 0.4842, 0.4223],\n",
      "          [0.3476, 0.6320, 0.6074, 0.4705, 0.4428, 0.3702, 0.4654],\n",
      "          [0.4222, 0.3432, 0.5025, 0.4354, 0.3696, 0.4783, 0.4894],\n",
      "          [0.3160, 0.6225, 0.5372, 0.4180, 0.4843, 0.5238, 0.2646],\n",
      "          [0.2224, 0.2415, 0.3129, 0.4583, 0.3823, 0.4688, 0.4855],\n",
      "          [0.5590, 0.3707, 0.3867, 0.6344, 0.3632, 0.5088, 0.3535],\n",
      "          [0.3616, 0.3910, 0.3547, 0.5794, 0.7729, 0.3745, 0.5003]],\n",
      "\n",
      "         [[0.3918, 0.4069, 0.2783, 0.4427, 0.5906, 0.6886, 0.5236],\n",
      "          [0.8435, 0.6493, 0.5113, 0.4448, 0.5222, 0.6143, 0.3225],\n",
      "          [0.5040, 0.5735, 0.6802, 0.4358, 0.3986, 0.3393, 0.4271],\n",
      "          [0.6695, 0.4078, 0.6237, 0.4108, 0.7149, 0.5540, 0.6401],\n",
      "          [0.6725, 0.6550, 0.5543, 0.4493, 0.6393, 0.4435, 0.6000],\n",
      "          [0.6929, 0.4651, 0.4148, 0.5704, 0.4754, 0.4266, 0.6648],\n",
      "          [0.5482, 0.5679, 0.5184, 0.3803, 0.5747, 0.3383, 0.4674]],\n",
      "\n",
      "         [[0.3036, 0.4015, 0.4807, 0.5284, 0.3349, 0.2866, 0.4318],\n",
      "          [0.5204, 0.2624, 0.5472, 0.4750, 0.4708, 0.4462, 0.3396],\n",
      "          [0.4194, 0.5249, 0.3799, 0.5003, 0.6362, 0.3779, 0.4069],\n",
      "          [0.4607, 0.4138, 0.6534, 0.6924, 0.4299, 0.3785, 0.3810],\n",
      "          [0.4904, 0.3825, 0.5144, 0.5639, 0.5281, 0.6694, 0.3951],\n",
      "          [0.4223, 0.3303, 0.4697, 0.5064, 0.4742, 0.7270, 0.4300],\n",
      "          [0.7976, 0.7296, 0.5113, 0.6384, 0.3882, 0.4167, 0.6313]],\n",
      "\n",
      "         [[0.3427, 0.4950, 0.5524, 0.4633, 0.3020, 0.5255, 0.3373],\n",
      "          [0.2954, 0.3779, 0.6500, 0.3805, 0.3842, 0.4902, 0.4441],\n",
      "          [0.3270, 0.5386, 0.3271, 0.4672, 0.6490, 0.3597, 0.4975],\n",
      "          [0.6452, 0.2513, 0.3635, 0.8430, 0.4048, 0.3190, 0.3003],\n",
      "          [0.5999, 0.4545, 0.4567, 0.2704, 0.4326, 0.5165, 0.3055],\n",
      "          [0.2182, 0.3956, 0.4787, 0.3115, 0.4469, 0.3214, 0.3893],\n",
      "          [0.4416, 0.2300, 0.3736, 0.4459, 0.5802, 0.4417, 0.3196]]],\n",
      "\n",
      "\n",
      "        [[[0.3938, 0.4867, 0.5067, 0.3419, 0.4512, 0.2990, 0.6057],\n",
      "          [0.4328, 0.5388, 0.4614, 0.4795, 0.2747, 0.5671, 0.3987],\n",
      "          [0.3558, 0.4601, 0.5817, 0.3996, 0.7283, 0.3340, 0.4796],\n",
      "          [0.2373, 0.3586, 0.5034, 0.5440, 0.4928, 0.4289, 0.4991],\n",
      "          [0.6439, 0.4624, 0.4578, 0.3796, 0.4680, 0.3508, 0.5430],\n",
      "          [0.5066, 0.4786, 0.3592, 0.6751, 0.3779, 0.4354, 0.2625],\n",
      "          [0.6647, 0.4887, 0.5038, 0.7828, 0.4950, 0.2498, 0.6356]],\n",
      "\n",
      "         [[0.4065, 0.6455, 0.4795, 0.4691, 0.3142, 0.3777, 0.5186],\n",
      "          [0.4549, 0.2685, 0.3174, 0.3373, 0.3973, 0.3227, 0.4522],\n",
      "          [0.5330, 0.3585, 0.3494, 0.3566, 0.3807, 0.3661, 0.3385],\n",
      "          [0.6321, 0.7558, 0.5301, 0.3841, 0.7757, 0.3161, 0.4094],\n",
      "          [0.2514, 0.4761, 0.4669, 0.3838, 0.3157, 0.6586, 0.3135],\n",
      "          [0.4736, 0.6087, 0.4659, 0.5171, 0.5510, 0.4099, 0.3453],\n",
      "          [0.5063, 0.5575, 0.6471, 0.5598, 0.5054, 0.3617, 0.4298]],\n",
      "\n",
      "         [[0.3743, 0.2887, 0.2212, 0.5104, 0.3246, 0.4975, 0.4366],\n",
      "          [0.3524, 0.1938, 0.5120, 0.5472, 0.6263, 0.4455, 0.3996],\n",
      "          [0.3140, 0.2996, 0.3294, 0.3094, 0.2816, 0.4313, 0.2894],\n",
      "          [0.5881, 0.3403, 0.3391, 0.3483, 0.4572, 0.2599, 0.2763],\n",
      "          [0.4343, 0.3678, 0.4469, 0.4943, 0.4188, 0.6210, 0.3554],\n",
      "          [0.4744, 0.4346, 0.6311, 0.2995, 0.3730, 0.3614, 0.4821],\n",
      "          [0.4633, 0.4061, 0.6371, 0.2833, 0.8271, 0.5571, 0.5760]],\n",
      "\n",
      "         [[0.6541, 0.4616, 0.4648, 0.4029, 0.6351, 0.4675, 0.3750],\n",
      "          [0.5698, 0.4386, 0.5456, 0.5334, 0.5443, 0.5909, 0.6849],\n",
      "          [0.3861, 0.6049, 0.6196, 0.5115, 0.5947, 0.5767, 0.3753],\n",
      "          [0.3915, 0.3994, 0.5586, 0.5195, 0.3473, 0.6947, 0.4975],\n",
      "          [0.4780, 0.4928, 0.6738, 0.6142, 0.4959, 0.6752, 0.6225],\n",
      "          [0.6175, 0.7035, 0.5930, 0.6321, 0.4641, 0.4925, 0.4715],\n",
      "          [0.4322, 0.6270, 0.6324, 0.4945, 0.4944, 0.4831, 0.3849]],\n",
      "\n",
      "         [[0.3692, 0.3532, 0.5262, 0.3995, 0.5493, 0.5330, 0.3664],\n",
      "          [0.2301, 0.4748, 0.5723, 0.7090, 0.3610, 0.3931, 0.4219],\n",
      "          [0.5864, 0.5889, 0.2454, 0.3470, 0.3814, 0.3675, 0.3262],\n",
      "          [0.4316, 0.3694, 0.3039, 0.3227, 0.6749, 0.5097, 0.4877],\n",
      "          [0.5227, 0.3040, 0.3914, 0.4100, 0.4988, 0.4925, 0.2997],\n",
      "          [0.3808, 0.3693, 0.2281, 0.8875, 0.7324, 0.5177, 0.3303],\n",
      "          [0.4486, 0.3537, 0.2566, 0.1882, 0.7300, 0.5810, 0.4902]],\n",
      "\n",
      "         [[0.4635, 0.4978, 0.3813, 0.3219, 0.5895, 0.5272, 0.4862],\n",
      "          [0.4875, 0.5142, 0.4136, 0.3349, 0.5968, 0.7614, 0.2312],\n",
      "          [0.4814, 0.3593, 0.4963, 0.5164, 0.3775, 0.3954, 0.3539],\n",
      "          [0.3671, 0.8256, 0.6095, 0.4114, 0.4246, 0.7090, 0.4947],\n",
      "          [0.7124, 0.4169, 0.5293, 0.4517, 0.5940, 0.4794, 0.5069],\n",
      "          [0.3982, 0.3905, 0.5109, 0.4148, 0.5303, 0.4106, 0.6645],\n",
      "          [0.3013, 0.5661, 0.3934, 0.3360, 0.5254, 0.7622, 0.3634]],\n",
      "\n",
      "         [[0.4478, 0.6045, 0.5920, 0.5714, 0.3256, 0.6443, 0.5448],\n",
      "          [0.4321, 0.5450, 0.4356, 0.2707, 0.4889, 0.4903, 0.3343],\n",
      "          [0.5897, 0.3621, 0.4489, 0.4980, 0.3307, 0.3126, 0.5016],\n",
      "          [0.4650, 0.4395, 0.2448, 0.2258, 0.3935, 0.2753, 0.5005],\n",
      "          [0.4129, 0.5028, 0.2556, 0.5739, 0.3650, 0.4851, 0.3286],\n",
      "          [0.4855, 0.8017, 0.5322, 0.2188, 0.3403, 0.6513, 0.4978],\n",
      "          [0.4251, 0.3514, 0.4658, 0.5689, 0.4573, 0.5967, 0.5227]],\n",
      "\n",
      "         [[0.4649, 0.3433, 0.3918, 0.2276, 0.5508, 0.4615, 0.3368],\n",
      "          [0.5770, 0.5161, 0.6064, 0.6602, 0.7213, 0.5688, 0.4543],\n",
      "          [0.5321, 0.4995, 0.5903, 0.4254, 0.7145, 0.4311, 0.6961],\n",
      "          [0.3670, 0.7309, 0.5398, 0.4490, 0.4238, 0.5495, 0.5822],\n",
      "          [0.3865, 0.4486, 0.5052, 0.5357, 0.3412, 0.4260, 0.6259],\n",
      "          [0.5078, 0.3146, 0.2882, 0.3739, 0.6561, 0.7087, 0.4810],\n",
      "          [0.3976, 0.4571, 0.5017, 0.6183, 0.4969, 0.4769, 0.3536]],\n",
      "\n",
      "         [[0.2412, 0.3632, 0.3583, 0.4941, 0.4588, 0.4960, 0.4477],\n",
      "          [0.3396, 0.4313, 0.5176, 0.5875, 0.3152, 0.4552, 0.6231],\n",
      "          [0.3100, 0.4246, 0.4686, 0.8352, 0.5568, 0.5563, 0.2628],\n",
      "          [0.6360, 0.4535, 0.5866, 0.4377, 0.4732, 0.2376, 0.5622],\n",
      "          [0.6499, 0.4952, 0.5828, 0.3310, 0.7033, 0.2682, 0.5264],\n",
      "          [0.5499, 0.5845, 0.4845, 0.5372, 0.4632, 0.6499, 0.3061],\n",
      "          [0.2256, 0.4389, 0.3056, 0.3437, 0.2977, 0.5442, 0.3938]],\n",
      "\n",
      "         [[0.3710, 0.3615, 0.4229, 0.3729, 0.5511, 0.4437, 0.5472],\n",
      "          [0.5363, 0.2830, 0.3263, 0.4657, 0.3970, 0.3656, 0.3527],\n",
      "          [0.2916, 0.4862, 0.4343, 0.2682, 0.3719, 0.4820, 0.5807],\n",
      "          [0.4097, 0.5889, 0.2824, 0.4797, 0.4132, 0.3940, 0.1874],\n",
      "          [0.2679, 0.4512, 0.5140, 0.3697, 0.3914, 0.3820, 0.7291],\n",
      "          [0.2995, 0.5114, 0.4285, 0.2885, 0.2115, 0.3548, 0.3119],\n",
      "          [0.3993, 0.3416, 0.3491, 0.4642, 0.3313, 0.3922, 0.4944]]]],\n",
      "       grad_fn=<LogBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from Capsule.Layer.CapsuleLayer import AdaptiveCapsuleHead\n",
    "import torch\n",
    "p = torch.randn(2, 512, 7, 7)\n",
    "# a = torch.randn(2, 512, 7, 7)\n",
    "params = {\n",
    "    \"n_cls\": 10,\n",
    "    \"n_layers\": 2,\n",
    "    \"n_emb\": 512,\n",
    "    \"is_caps\": False,\n",
    "    \"caps\": {\n",
    "        \"reduce\": True,\n",
    "        \"cap_dims\": 4,\n",
    "        \"routing\":{\n",
    "                \"type\": \"em\",\n",
    "                \"iters\": 3,\n",
    "                \"temp\": 1.5,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "adaptive_capsule_head = AdaptiveCapsuleHead(512, head=params)\n",
    "adaptive_capsule_head.eval()\n",
    "a_out = adaptive_capsule_head(p)\n",
    "print(a_out.shape)\n",
    "print(a_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
